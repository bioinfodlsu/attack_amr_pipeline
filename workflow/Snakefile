# This defines the input files for each sample using glob_wildcards.
# The input files are located in the "data" directory and have the pattern:
# 	{sample}_R1.fastq.gz
# The pattern is used to extract the sample name and store it in the "SAMPLES" variable.


(SAMPLES,) = glob_wildcards("data/{sample}_R1.fastq.gz")


# This defines the output files for the pipeline.
rule all:
	input:
		expand("data/FASTQC/{sample}_{read}_fastqc.zip", sample=SAMPLES, read=["R1", "R2"]),
		"data/multiqc_report.html",
		expand("trimmed_data/{sample}_{read}_trimmed.fastq.gz", sample=SAMPLES,	read=["R1", "R2"]),
		expand("trimmed_data/FASTQC/{sample}_{read}_trimmed_fastqc.zip", sample=SAMPLES, read=["R1", "R2"]),
		"trimmed_data/multiqc_report.html",
		# Uncomment to run using Resfinder database
		# "resfinder_db/resfinder.1.bt2",
		#"resfinder_db/resfinder_length.txt",
		# expand("mapped_reads_resfinder/{sample}_unfiltered.bam", sample=SAMPLES),
		# expand("logs/resfinder/{sample}.log", sample=SAMPLES),
		# expand("mapped_reads_resfinder/{sample}.bam", sample=SAMPLES),
		# expand("sorted_reads_resfinder/{sample}.bam.bai", sample=SAMPLES),
		# "resfinder_out/gene_names",
		# "resfinder_out/ARG_genemat.txt",
		# Uncomment to run using CARD database
		"card_db/card.1.bt2",
		"card_db/card_length.txt",
		expand("mapped_reads_card/{sample}_unfiltered.bam", sample=SAMPLES),
		expand("logs/card/{sample}.log", sample=SAMPLES),
		expand("mapped_reads_card/{sample}.bam", sample=SAMPLES),
		expand("sorted_reads_card/{sample}.bam.bai", sample=SAMPLES),
		"card_out/gene_names",
		"card_out/ARG_genemat.txt",
		# Uncomment to run using ISFinder database
		"ISFinder_db/ISFinder.1.bt2",
		"ISFinder_db/ISFinder_length.txt",
		expand("mapped_reads_ISFinder/{sample}_unfiltered.bam", sample=SAMPLES),
		expand("logs/ISFinder/{sample}.log", sample=SAMPLES),
		expand("mapped_reads_ISFinder/{sample}.bam", sample=SAMPLES),
		expand("sorted_reads_ISFinder/{sample}.bam.bai", sample=SAMPLES),
		"ISFinder_out/gene_names",
		"ISFinder_out/ISFinder_genemat.txt",
		# Uncomment to run using INTEGRALL database
		"integrall_db/integrall.1.bt2",
		"integrall_db/integrall_length.txt",
		expand("mapped_reads_integrall/{sample}_unfiltered.bam", sample=SAMPLES),
		expand("logs/integrall/{sample}.log", sample=SAMPLES),
		expand("mapped_reads_integrall/{sample}.bam", sample=SAMPLES),
		expand("sorted_reads_integrall/{sample}.bam.bai", sample=SAMPLES),
		"integrall_out/gene_names",
		"integrall_out/integrall_genemat.txt",
		# Uncomment to run using PlasmidFinder database
		"PlasmidFinder_db/PlasmidFinder.1.bt2",
		"PlasmidFinder_db/PlasmidFinder_length.txt",
		expand("mapped_reads_PlasmidFinder/{sample}_unfiltered.bam", sample=SAMPLES),
		expand("logs/PlasmidFinder/{sample}.log", sample=SAMPLES),
		expand("mapped_reads_PlasmidFinder/{sample}.bam", sample=SAMPLES),
		expand("sorted_reads_PlasmidFinder/{sample}.bam.bai", sample=SAMPLES),
		"PlasmidFinder_out/gene_names",
		"PlasmidFinder_out/PlasmidFinder_genemat.txt",
		#Uncomment to run Metaphlan
		#expand("metaphlan/{sample}_profile.txt", sample=SAMPLES),
		# "metaphlan/merged_abundance_table.txt",
		#Uncomment to run Kraken2
		expand("kraken2/{sample}.tab", sample=SAMPLES),
		expand("kraken2/{sample}_breport", sample=SAMPLES),
		expand("kraken2/{sample}_bracken.tab", sample=SAMPLES),
		expand("kreport2mpa/{sample}_mpa.tab", sample=SAMPLES),
		expand("kreport2mpa_norm/{sample}_profile.tab", sample=SAMPLES),
		"kreport2mpa_norm/merged_metakraken_abundance_table.txt"

# Perform quality control on raw sequencing data using FastQC.
rule fastqc_raw:
	input:
		"data/{sample}_{read}.fastq.gz",
	output:
		"data/FASTQC/{sample}_{read}_fastqc.zip",
	message:
		"-- Quality check of raw data with Fastqc --"
	conda:
		"envs/fastqc.yml"
	threads: 20
	shell:
		"fastqc --quiet -t {threads} --outdir data/FASTQC -f fastq {input}"


# Aggregate FastQC results for raw data into a single MultiQC report.
rule multiqc_raw:
	input:
		expand(
			"data/FASTQC/{sample}_{read}_fastqc.zip",
			sample=SAMPLES,
			read=["R1", "R2"],
		),
	output:
		"data/multiqc_report.html",
	message:
		"-- Running MultiQC for raw data --"
	conda:
		"envs/multiqc.yml"
	threads: 20
	shell:
		"multiqc -f --interactive --quiet data/ -o data/"


# Trim adapter sequences and low-quality bases from raw sequencing data using Cutadapt.
rule cutadapt:
	input:
		fw="data/{sample}_R1.fastq.gz",
		rv="data/{sample}_R2.fastq.gz"
	output:
		fw="trimmed_data/{sample}_R1_trimmed.fastq.gz",
		rv="trimmed_data/{sample}_R2_trimmed.fastq.gz",
		log="trimmed_data/{sample}.trimmed.txt"
	message:
		"-- Running Cutadapt --"
	conda:
		"envs/cutadapt.yml"
	threads: 20
	shell:
		"cutadapt -a CTGTCTCTTATACACATCT -A CTGTCTCTTATACACATCT -O 10 -m 30 -q 20 {input.fw} {input.rv} -o {output.fw} -p {output.rv} > {output.log}"

# Perform quality control on trimmed sequencing data using FastQC.
rule fastqc_trim:
	input:
		"trimmed_data/{sample}_{read}_trimmed.fastq.gz",
	output:
		"trimmed_data/FASTQC/{sample}_{read}_trimmed_fastqc.zip",
	message:
		"-- Quality check of trimmed data with Fastqc --"
	conda:
		"envs/fastqc.yml"
	threads: 20
	shell:
		"fastqc --quiet -t {threads} --outdir trimmed_data/FASTQC -f fastq {input}"

# Aggregate FastQC results for trimmed data into a single MultiQC report.
rule multiqc_trim:
	input:
		expand(
			"trimmed_data/FASTQC/{sample}_{read}_trimmed_fastqc.zip",
			sample=SAMPLES,
			read=["R1", "R2"],
		),
	output:
		"trimmed_data/multiqc_report.html",
	message:
		"-- Running MultiQC for trimmed data--"
	conda:
		"envs/multiqc.yml"
	threads: 20
	shell:
		"multiqc -f --interactive --quiet trimmed_data/ -o trimmed_data/"

# -------------------------- Start of Resfinder Database ----------------------------#

rule resfinder_db:
	input:
		fasta="resfinder_db/resfinder.fasta"
	output:
		indexed_db="resfinder_db/resfinder.1.bt2"
	message:
		"-- Creating ResFinder database --"	 
	conda:
		"envs/bowtie2.yml"
	threads: 20
	shell:
		"bowtie2-build {input.fasta} resfinder_db/resfinder"

rule resfinder_length:
	input:
		fasta="resfinder_db/resfinder.fasta"
	output:
		"resfinder_db/resfinder_length.txt"
	message:
		"-- Creating ResFinder length file --"
	conda:
		"envs/bowtie2.yml"
	threads: 20
	shell:
		"""
        echo 'GENE\tLength' > {output}
        bioawk -c fastx '{{ print $name, length($seq) }}' {input.fasta} >> {output}
        """
rule resfinder_mapping:
	input:
		fw="trimmed_data/{sample}_R1_trimmed.fastq.gz",
		rv="trimmed_data/{sample}_R2_trimmed.fastq.gz",
		indexed_db="resfinder_db/resfinder.1.bt2"
	output:
		"mapped_reads_resfinder/{sample}_unfiltered.bam"
	log:
		"logs/resfinder/{sample}.log"
	message:
		"-- Mapping reads to ResFinder database and extracting mapped reads --"
	conda:
		"envs/bowtie2.yml"
	threads: 20
	shell:
		"""
		(bowtie2 -x resfinder_db/resfinder -1 {input.fw} -2 {input.rv} -p {threads} -D 20 -R 3 -N 1 -L 20 -i S,1,0.50 | \
		samtools view -Sb - > {output}) 2> {log}
		"""

rule resfinder_filtering:
	input:
		"mapped_reads_resfinder/{sample}_unfiltered.bam"
	output:
		"mapped_reads_resfinder/{sample}.bam"
	message:
		"-- Filtering reads before sorting --"
	conda:
		"envs/bowtie2.yml"
	threads: 20
	shell: 
		"""
		samtools view -h {input} | gawk 'BEGIN {{FS="\t"; OFS="\t"}} \
		{{if (/^@/ && substr($2, 3, 1)==":") {{print}} \
		else if (($7!="=" || $7=="=") && and($2, 0x40)) {{print}}}}' \
		| samtools view -Shu - > {output}
		"""

rule resfinder_sorting:
	input:
		"mapped_reads_resfinder/{sample}.bam"
	output:
		"sorted_reads_resfinder/{sample}.bam"
	message:
		"-- Sorting reads --"
	conda:
		"envs/bowtie2.yml"
	threads: 20
	shell:
		"samtools sort -T sorted_reads_resfinder/{wildcards.sample} -O bam {input} > {output}"

rule resfinder_indexing:
	input:
		"sorted_reads_resfinder/{sample}.bam"
	output:
		"sorted_reads_resfinder/{sample}.bam.bai"
	message:
		"-- Indexing mapped reads --"
	conda:
		"envs/bowtie2.yml"
	threads: 20
	shell:
		"samtools index {input}"


rule combine_results_1:
	input:
        "sorted_reads_resfinder/{sample}.bam".format(sample=SAMPLES[0])
	output:
		"resfinder_out/gene_names"
	message:
		"-- Creating gene_names file --"
	conda:
		"envs/bowtie2.yml"
	threads: 20
	shell:
		"""
		samtools idxstats {input} | grep -v "\*" | cut -f1 > {output}
		sed -i '1 i\GENE' {output}
		"""

rule combine_results_2:
	input:
		"sorted_reads_resfinder/{sample}.bam"
	output:
		"resfinder_out/{sample}_counts"
	message:
		"-- Combine count data into genemat --"
	conda:
		"envs/bowtie2.yml"
	threads: 20
	shell:
		'samtools idxstats {input} | grep -v "\*" | cut -f3 > {output}'

rule combine_results_3:
	input:
		"resfinder_out/{sample}_counts"
	output:
		"resfinder_out/renamed_{sample}_counts"
	message:
		"-- Adding sample names --"
	threads: 20
	shell:
		"sed '1 i\{wildcards.sample}' {input} > {output}"

rule combine_results_4:
	input:
		gene_names="resfinder_out/gene_names",
		counts=expand("resfinder_out/renamed_{sample}_counts", sample=SAMPLES)
	output:
		"resfinder_out/ARG_genemat.txt",
	message:
		"-- Creating ARG_genemat --"
	threads: 20
	shell:
		"paste {input.gene_names} {input.counts} > {output}"

# -------------------------- End of Resfinder Database ----------------------------#

# -------------------------- Start of Card Database -------------------------------#

rule card_db:
	input:
		fasta="card_db/card.fasta",
	output:
		indexed_db="card_db/card.1.bt2",
	message:
		"-- Creating Card database --" 
	conda:
		"envs/bowtie2.yml"
	threads: 20
	shell:
		"bowtie2-build {input.fasta} card_db/card"

rule card_length:
	input:
		fasta="card_db/card.fasta",
	output:
		"card_db/card_length.txt",
	message:
		"-- Creating Card length file --"
	conda:
		"envs/bowtie2.yml"
	threads: 20
	shell:
		"""
		echo 'GENE\tLength' > {output}
		bioawk -c fastx '{{ print $name, length($seq) }}' {input.fasta} >> {output}
		"""

rule card_mapping:
	input:
		fw="trimmed_data/{sample}_R1_trimmed.fastq.gz",
		rv="trimmed_data/{sample}_R2_trimmed.fastq.gz",
		indexed_db="card_db/card.1.bt2",
	output:
		"mapped_reads_card/{sample}_unfiltered.bam",
	log:
		"logs/card/{sample}.log",
	message:
		"-- Mapping reads to Card database and extracting mapped reads --"
	conda:
		"envs/bowtie2.yml"
	threads: 20
	shell:
		"""
		(bowtie2 -x card_db/card -1 {input.fw} -2 {input.rv} -p {threads} -D 20 -R 3 -N 1 -L 20 -i S,1,0.50 | \
		samtools view -Sb - > {output}) 2> {log}
		"""

rule card_filtering:
	input:
		"mapped_reads_card/{sample}_unfiltered.bam",
	output:
		"mapped_reads_card/{sample}.bam",
	message:
		"-- Filtering reads before sorting --"
	conda:
		"envs/bowtie2.yml"
	threads: 20
	shell:
		"""
		samtools view -h {input} | gawk 'BEGIN {{FS="\t"; OFS="\t"}} \
		{{if (/^@/ && substr($2, 3, 1)==":") {{print}} \
		else if (($7!="=" || $7=="=") && and($2, 0x40)) {{print}}}}' \
		| samtools view -Shu - > {output}
		"""

rule card_sorting:
	input:
		"mapped_reads_card/{sample}.bam",
	output:
		"sorted_reads_card/{sample}.bam",
	message:
		"-- Sorting reads --"
	conda:
		"envs/bowtie2.yml"
	threads: 20
	shell:
		"samtools sort -T sorted_reads_card/{wildcards.sample} -O bam {input} > {output}"

rule card_indexing:
	input:
		"sorted_reads_card/{sample}.bam",
	output:
		"sorted_reads_card/{sample}.bam.bai",
	message:
		"-- Indexing mapped reads --"
	conda:
		"envs/bowtie2.yml"
	threads: 20
	shell:
		"samtools index {input}"

rule combine_results_card_1:
	input:
        "sorted_reads_card/{sample}.bam".format(sample=SAMPLES[0])
	output:
		"card_out/gene_names",
	message:
		"-- Creating gene_names file --"
	conda:
		"envs/bowtie2.yml"
	threads: 20
	shell:
		"""
		samtools idxstats {input} | grep -v "\*" | cut -f1 > {output}
		sed -i '1 i\GENE' {output}
		"""

rule combine_results_card_2:
	input:
		"sorted_reads_card/{sample}.bam",
	output:
		"card_out/{sample}_counts",
	message:
		"-- Combine count data into genemat --"
	conda:
		"envs/bowtie2.yml"
	threads: 20
	shell:
		'samtools idxstats {input} | grep -v "\*" | cut -f3 > {output}'

rule combine_results_card_3:
	input:
		"card_out/{sample}_counts",
	output:
		"card_out/renamed_{sample}_counts",
	message:
		"-- Adding sample names --"
	threads: 20
	shell:
		"sed '1 i\{wildcards.sample}' {input} > {output}"

rule combine_results_card_4:
	input:
		gene_names="card_out/gene_names",
		counts=expand("card_out/renamed_{sample}_counts", sample=SAMPLES),
	output:
		"card_out/ARG_genemat.txt",
	message:
		"-- Creating ARG_genemat --"
	threads: 20
	shell:
		"paste {input.gene_names} {input.counts} > {output}"

# -------------------------- End of Card Database -------------------------------#

# ----------------------- Start of ISFinder DB ----------------------------------#
rule ISFinder_db:
	input:
		fasta="ISFinder_db/ISFinder.fasta",
	output:
		indexed_db="ISFinder_db/ISFinder.1.bt2",
	message:
		"-- IS db --"
	conda:
		"envs/bowtie2.yml"
	threads: 20
	shell:
		"bowtie2-build {input.fasta} ISFinder_db/ISFinder"
rule ISFinder_length:
	input:
		fasta="ISFinder_db/ISFinder.fasta",
	output:
		"ISFinder_db/ISFinder_length.txt",
	message:
		"-- Creating IS length file --"
	conda:
		"envs/bowtie2.yml"
	threads: 20
	shell:
		"""
        echo 'GENE\tLength' > {output}
        bioawk -c fastx '{{ print $name, length($seq) }}' {input.fasta} >> {output}
        """
rule ISFinder_mapping:
	input:
		fw="trimmed_data/{sample}_R1_trimmed.fastq.gz",
		rv="trimmed_data/{sample}_R2_trimmed.fastq.gz",
		indexed_db="ISFinder_db/ISFinder.1.bt2",
	output:
		"mapped_reads_ISFinder/{sample}_unfiltered.bam",
	log:
		"logs/ISFinder/{sample}.log",
	message:
		"-- Mapping w/ ISs --"
	conda:
		"envs/bowtie2.yml"
	threads: 20
	shell:
		"""
		(bowtie2 -x ISFinder_db/ISFinder -1 {input.fw} -2 {input.rv} -p {threads} -D 20 -R 3 -N 1 -L 20 -i S,1,0.50 | \
		samtools view -Sb - > {output}) 2> {log}
		"""
rule ISFinder_filtering:
	input:
		"mapped_reads_ISFinder/{sample}_unfiltered.bam",
	output:
		"mapped_reads_ISFinder/{sample}.bam",
	message:
		"-- Filtering reads for sorting --"
	conda:
		"envs/bowtie2.yml"
	threads: 20
	shell:
		"""
		samtools view -h {input} | gawk 'BEGIN {{FS="\t"; OFS="\t"}} \
		{{if (/^@/ && substr($2, 3, 1)==":") {{print}} \
		else if (($7!="=" || $7=="=") && and($2, 0x40)) {{print}}}}' \
		| samtools view -Shu - > {output}
		"""
rule ISFinder_sorting:
	input:
		"mapped_reads_ISFinder/{sample}.bam",
	output:
		"sorted_reads_ISFinder/{sample}.bam",
	message:
		"-- Sorting reads --"
	conda:
		"envs/bowtie2.yml"
	threads: 20
	shell:
		"samtools sort -T sorted_reads_ISFinder/{wildcards.sample} -O bam {input} > {output}"

rule ISFinder_indexing:
	input:
		"sorted_reads_ISFinder/{sample}.bam",
	output:
		"sorted_reads_ISFinder/{sample}.bam.bai",
	message:
		"-- Indexing mapped reads --"
	conda:
		"envs/bowtie2.yml"
	threads: 20
	shell:
		"samtools index {input}"
SAMPLE1 = "UST6"
rule combine_ISFinder_results_1:
    input:
        "sorted_reads_ISFinder/{sample}.bam".format(sample=SAMPLES[0])
    output:
        "ISFinder_out/gene_names"
    message:
        "-- Creating gene_names file --"
    conda:
        "envs/bowtie2.yml"
    threads: 20
    shell:
        """
        samtools idxstats {input} | grep -v "\*" | cut -f1 > {output}
        sed -i '1 i\GENE' {output}
        """
rule combine_ISFinder_results_2:
	input:
		"sorted_reads_ISFinder/{sample}.bam",
	output:
		"ISFinder_out/{sample}_counts",
	message:
		"-- Combine count data into genemat --"
	conda:
		"envs/bowtie2.yml"
	threads: 20
	shell:
		"""
		samtools idxstats {input} | grep -v "\*" | cut -f3 > {output}
		"""
rule combine_ISFinder_results_3:
	input:
		"ISFinder_out/{sample}_counts",
	output:
		"ISFinder_out/renamed_{sample}_counts",
	message:
		"-- Adding sample names --"
	threads: 20
	shell:
		"sed '1 i\{wildcards.sample}' {input} > {output}"

rule combine_ISFinder_results_4:
	input:
		gene_names="ISFinder_out/gene_names",
		counts=expand("ISFinder_out/renamed_{sample}_counts", sample=SAMPLES)
	output:
		"ISFinder_out/ISFinder_genemat.txt",
	message:
		"-- Creating ISFinder_genemat --"
	threads: 20
	shell:
		"paste {input.gene_names} {input.counts} > {output}"
# ----------------------- End of ISFinder DB ----------------------------------#

# ----------------------- Start of INTEGRALL DB -------------------------------#

rule integrall_db:
	input:
		fasta="integrall_db/integrall.fasta",
	output:
		indexed_db="integrall_db/integrall.1.bt2",
	message:
		"-- integrall db --"
	conda:
		"envs/bowtie2.yml"
	threads: 20
	shell:
		"bowtie2-build {input.fasta} integrall_db/integrall"
rule integrall_length:
	input:
		fasta="integrall_db/integrall.fasta",
	output:
		"integrall_db/integrall_length.txt",
	message:
		"-- Creating integrall length file --"
	conda:
		"envs/bowtie2.yml"
	threads: 20
	shell:
		"""
        echo 'GENE\tLength' > {output}
        bioawk -c fastx '{{ print $name, length($seq) }}' {input.fasta} >> {output}
        """
rule integrall_mapping:
	input:
		fw="trimmed_data/{sample}_R1_trimmed.fastq.gz",
		rv="trimmed_data/{sample}_R2_trimmed.fastq.gz",
		indexed_db="integrall_db/integrall.1.bt2",
	output:
		"mapped_reads_integrall/{sample}_unfiltered.bam",
	log:
		"logs/integrall/{sample}.log",
	message:
		"-- Mapping w/ integrall --"
	conda:
		"envs/bowtie2.yml"
	threads: 20
	shell:
		"""
		(bowtie2 -x integrall_db/integrall -1 {input.fw} -2 {input.rv} -p {threads} -D 20 -R 3 -N 1 -L 20 -i S,1,0.50 | \
		samtools view -Sb - > {output}) 2> {log}
		"""
rule integrall_filtering:
	input:
		"mapped_reads_integrall/{sample}_unfiltered.bam",
	output:
		"mapped_reads_integrall/{sample}.bam",
	message:
		"-- Filtering reads for sorting --"
	conda:
		"envs/bowtie2.yml"
	threads: 20
	shell:
		"""
		samtools view -h {input} | gawk 'BEGIN {{FS="\t"; OFS="\t"}} \
		{{if (/^@/ && substr($2, 3, 1)==":") {{print}} \
		else if (($7!="=" || $7=="=") && and($2, 0x40)) {{print}}}}' \
		| samtools view -Shu - > {output}
		"""
rule integrall_sorting:
	input:
		"mapped_reads_integrall/{sample}.bam",
	output:
		"sorted_reads_integrall/{sample}.bam",
	message:
		"-- Sorting reads --"
	conda:
		"envs/bowtie2.yml"
	threads: 20
	shell:
		"samtools sort -T sorted_reads_integrall/{wildcards.sample} -O bam {input} > {output}"

rule integrall_indexing:
	input:
		"sorted_reads_integrall/{sample}.bam",
	output:
		"sorted_reads_integrall/{sample}.bam.bai",
	message:
		"-- Indexing mapped reads --"
	conda:
		"envs/bowtie2.yml"
	threads: 20
	shell:
		"samtools index {input}"
	
rule combine_integrall_results_1:
    input:
        "sorted_reads_integrall/{sample}.bam".format(sample=SAMPLES[0])
    output:
        "integrall_out/gene_names"
    message:
        "-- Creating gene_names file --"
    conda:
        "envs/bowtie2.yml"
    threads: 20
    shell:
        """
        samtools idxstats {input} | grep -v "\*" | cut -f1 > {output}
        sed -i '1 i\GENE' {output}
        """
rule combine_integrall_results_2:
	input:
		"sorted_reads_integrall/{sample}.bam",
	output:
		"integrall_out/{sample}_counts",
	message:
		"-- Combine count data into genemat --"
	conda:
		"envs/bowtie2.yml"
	threads: 20
	shell:
		"""
		samtools idxstats {input} | grep -v "\*" | cut -f3 > {output}
		"""
rule combine_integrall_results_3:
	input:
		"integrall_out/{sample}_counts",
	output:
		"integrall_out/renamed_{sample}_counts",
	message:
		"-- Adding sample names --"
	threads: 20
	shell:
		"sed '1 i\{wildcards.sample}' {input} > {output}"

rule combine_integrall_results_4:
	input:
		gene_names="integrall_out/gene_names",
		counts=expand("integrall_out/renamed_{sample}_counts", sample=SAMPLES),
	output:
		"integrall_out/integrall_genemat.txt",
	message:
		"-- Creating integrall_genemat --"
	threads: 20
	shell:
		"paste {input.gene_names} {input.counts} > {output}"
# ----------------------- End of INTEGRALL DB -------------------------------#

# -------------------- Start of PlasmidFinder DB ----------------------------#

rule PlasmidFinder_db:
	input:
		fasta="PlasmidFinder_db/PlasmidFinder.fasta",
	output:
		indexed_db="PlasmidFinder_db/PlasmidFinder.1.bt2",
	message:
		"-- PlasmidFinder db --"
	conda:
		"envs/bowtie2.yml"
	threads: 20
	shell:
		"bowtie2-build {input.fasta} PlasmidFinder_db/PlasmidFinder"

rule PlasmidFinder_length:
	input:
		fasta="PlasmidFinder_db/PlasmidFinder.fasta",
	output:
		"PlasmidFinder_db/PlasmidFinder_length.txt",
	message:
		"-- Creating PlasmidFinder length file --"
	conda:
		"envs/bowtie2.yml"
	threads: 20
	shell:
		"""
        echo 'GENE\tLength' > {output}
        bioawk -c fastx '{{ print $name, length($seq) }}' {input.fasta} >> {output}
        """
rule PlasmidFinder_mapping:
	input:
		fw="trimmed_data/{sample}_R1_trimmed.fastq.gz",
		rv="trimmed_data/{sample}_R2_trimmed.fastq.gz",
		indexed_db="PlasmidFinder_db/PlasmidFinder.1.bt2",
	output:
		"mapped_reads_PlasmidFinder/{sample}_unfiltered.bam",
	log:
		"logs/PlasmidFinder/{sample}.log",
	message:
		"-- Mapping w/ plasmids --"
	conda:
		"envs/bowtie2.yml"
	threads: 20
	shell:
		"""
		(bowtie2 -x PlasmidFinder_db/PlasmidFinder -1 {input.fw} -2 {input.rv} -p {threads} -D 20 -R 3 -N 1 -L 20 -i S,1,0.50 | \
		samtools view -Sb - > {output}) 2> {log}
		"""
rule PlasmidFinder_filtering:
	input:
		"mapped_reads_PlasmidFinder/{sample}_unfiltered.bam",
	output:
		"mapped_reads_PlasmidFinder/{sample}.bam",
	message:
		"-- Filtering reads for sorting --"
	conda:
		"envs/bowtie2.yml"
	threads: 20
	shell:
		"""
		samtools view -h {input} | gawk 'BEGIN {{FS="\t"; OFS="\t"}} \
		{{if (/^@/ && substr($2, 3, 1)==":") {{print}} \
		else if (($7!="=" || $7=="=") && and($2, 0x40)) {{print}}}}' \
		| samtools view -Shu - > {output}
		"""
rule PlasmidFinder_sorting:
	input:
		"mapped_reads_PlasmidFinder/{sample}.bam",
	output:
		"sorted_reads_PlasmidFinder/{sample}.bam",
	message:
		"-- Sorting reads --"
	conda:
		"envs/bowtie2.yml"
	threads: 20
	shell:
		"samtools sort -T sorted_reads_PlasmidFinder/{wildcards.sample} -O bam {input} > {output}" 
rule PlasmidFinder_indexing:
	input:
		"sorted_reads_PlasmidFinder/{sample}.bam",
	output:
		"sorted_reads_PlasmidFinder/{sample}.bam.bai",
	message:
		"-- Indexing mapped reads --"
	conda:
		"envs/bowtie2.yml"
	threads: 20
	shell:
		"samtools index {input}"


rule combine_PlasmidFinder_results_1:
    input:
        "sorted_reads_PlasmidFinder/{sample}.bam".format(sample=SAMPLES[0])
    output:
        "PlasmidFinder_out/gene_names"
    message:
        "-- Creating gene_names file --"
    conda:
        "envs/bowtie2.yml"
    threads: 20
    shell:
        """
        samtools idxstats {input} | grep -v "\*" | cut -f1 > {output}
        sed -i '1 i\GENE' {output}
        """
rule combine_PlasmidFinder_results_2:
	input:
		"sorted_reads_PlasmidFinder/{sample}.bam",
	output:
		"PlasmidFinder_out/{sample}_counts",
	message:
		"-- Combine count data into genemat --"
	conda:
		"envs/bowtie2.yml"
	threads: 20
	shell:
		"""
		samtools idxstats {input} | grep -v "\*" | cut -f3 > {output}
		"""
rule combine_PlasmidFinder_results_3:
	input:
		"PlasmidFinder_out/{sample}_counts",
	output:
		"PlasmidFinder_out/renamed_{sample}_counts",
	message:
		"-- Adding sample names --"
	threads: 20
	shell:
		"sed '1 i\{wildcards.sample}' {input} > {output}"

rule combine_PlasmidFinder_results_4:
	input:
		gene_names="PlasmidFinder_out/gene_names",
		counts=expand("PlasmidFinder_out/renamed_{sample}_counts", sample=SAMPLES),
	output:
		"PlasmidFinder_out/PlasmidFinder_genemat.txt",
	message:
		"-- Creating PlasmidFinder_genemat --"
	threads: 20
	shell:
		"paste {input.gene_names} {input.counts} > {output}"
# -------------------- End of PlasmidFinder DB ----------------------------#

# ----------------------- Start of Metaphlan ------------------------------#

rule metaphlan:
	input:
		read1="trimmed_data/{sample}_R1_trimmed.fastq.gz",
		read2="trimmed_data/{sample}_R2_trimmed.fastq.gz",
	output:
		file="metaphlan/{sample}_profile.txt",
		bowtie2out="metaphlan/{sample}.bowtie2.bz2",
	message:
		"-- Running Metaphlan --"
	conda:
		"envs/metaphlan.yml"
	threads: 20
	shell:
	"metaphlan -t rel_ab_w_read_stats --bowtie2db metaphlan/ {input.read1},{input.read2} --nproc {threads} --bowtie2out {output.bowtie2out} --sample_id {wildcards.sample} --input_type fastq > {output.file}"

rule metaphlan_merge:
	input:
		expand("metaphlan/{sample}_profile.txt", sample=SAMPLES),
	output:
		"metaphlan/merged_abundance_table.txt",
	message:
		"-- Merging Metaphlan results into table --"
	conda:
		"envs/metaphlan.yml"
	threads: 20
	shell:
		"merge_metaphlan_tables.py {input} > {output}"
# ----------------------- End of Metaphlan ------------------------------#

# ----------------------- Start of Kraken2 ------------------------------#

rule kraken2:
	input:
		read1="trimmed_data/{sample}_R1_trimmed.fastq.gz",
		read2="trimmed_data/{sample}_R2_trimmed.fastq.gz"
	output:
		kraken = "kraken2/{sample}.kraken2",
		report = "kraken2/{sample}.tab"
	message:
		"-- Running Kraken2 --"
	conda:
		"envs/kraken2.yml"
	threads: 20
	shell:
		"kraken2 --db kraken2_db --threads {threads} --paired --output {output.kraken} --report {output.report} {input.read1} {input.read2}"


#Geneate bracken report in tsv format
rule bracken:
	input:
		kraken="kraken2/{sample}.tab"
	output:
		br1 = "kraken2/{sample}_breport",
		br2 = "kraken2/{sample}_bracken.tab"
	message:
		"-- Running Bracken --"
	conda:
		"envs/kraken2.yml"
	threads: 20
	shell:
		"bracken -d kraken2_db -i {input} -l G -t 150 -r 250 -o {output.br1}"


# Bracken to Metaphlan Format
rule bracken_to_metaphlan:
	input:
		report = "kraken2/{sample}_bracken.tab"
	output:
		mpa = "kreport2mpa/{sample}_mpa.tab"
	message:
		"-- Combining Bracken results into Metaphlan format --"
	conda:
		"envs/kraken2.yml"
	shell:
		"""
		kreport2mpa.py -r {input} -o {output}
		"""
rule normalize_to_mpa:
	input:
		r1 = "kreport2mpa/{sample}_mpa.tab"
	output:
		"kreport2mpa_norm/{sample}_profile.tab"
	message:
		"-- Normalizing Bracken results to Metaphlan format --"
	shell:
		"""
        sum=$(grep -vP "\\|" {input} | cut -f 2 | awk '{{sum += $1}} END {{printf ("%.2f\\n", sum/100)}}')
        awk -v sum="$sum" 'BEGIN {{FS="\\t"}} {{OFS="\\t"}} {{print $1,$2/sum}}' {input} > {output}
        """

rule merge_mpa:
	input:
		expand("kreport2mpa_norm/{sample}_profile.tab", sample=SAMPLES)
	output:
	    merge = "kreport2mpa_norm/merged_metakraken_abundance_table.txt"
	conda:
		"envs/metaphlan2.yml"
	shell:
		"""
		merge_metaphlan_tables.py {input} >  {output.merge}
		"""
# ----------------------- End of Kraken2 ------------------------------#






